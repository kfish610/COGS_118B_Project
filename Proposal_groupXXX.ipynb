{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Anna Sim\n",
    "- Jing Yin (Trevor) Yip\n",
    "- Kevin Fisher\n",
    "- Ashesh Kaji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This project aims to enhance the interpretability of relationships within word embeddings generated by large language models (LLMs), specifically focusing on Word2Vec embeddings. Understanding LLMs is crucial, especially as they are increasingly used in high-risk environments where comprehension of their predictions is vital. While prior studies have identified analytical relationships between words within these embeddings, these observations have been limited and hand-picked.\n",
    "\n",
    "To address this, we propose a clustering approach on the relationships between word pairs within the dataset. This allows distinct groups of similar relationships to emerge, offering insights into related points within each cluster and potentially revealing unconsidered relationships. We calculate relationships between words by taking the vector difference and ensure comparability through hyperplane splitting.\n",
    "\n",
    "The solution's performance will be evaluated using the silhouette score, which measures cluster density and separation. Additionally, we will manually inspect clusters to ensure known relationships (e.g., capital/country) are grouped logically. This project poses minimal privacy risks but necessitates careful consideration of existing biases within the Word2Vec dataset, which could impact training data and lead to biased analogical reasoning capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "In recent years, there has been a drastic increase in the implementation of large language models (LLM). LLMs accelerated the development of tools like recommendation systems, language sentiment analysis, and machine translation. The increased use of the language models requires further analysis and interpretation work to ensure responsible use of the architectures and models. High-risk environments require not only high accuracy of the predictions but also an understanding of why the model makes certain predictions[4]. As users rely more and more on machine learning systems to make decisions, there is an increasing risk of misuse and misinterpretation of the results and capabilities of the system. Therefore, there is a demand for interpretability research both in academia and industry.\n",
    "\n",
    "Interpretability of results of language models depends on understanding the relationships between semantic and syntactic content of words and their vector representations. Word2Vec is a popular algorithm developed by Tomas Mikolov et al. in 2013, which revolutionized the world of language models by proposing a new method of creating such continuous vector representations of words<a name=\"Linzen\"></a>[<sup>[2]</sup>](#Linzennote). Preliminary analysis of Word2Vec embeddings showed that the vector representation captures relationships between the words. In the original paper, the authors showed how similar words are not only represented with vectors that have high cosine similarity, but also exhibit complex relationships like vector(“smallest”) = vector(”biggest”) - vector(”big”) + vector(”small”). They also show intricate semantic relationships, like country/city relationships and syntactic relationships from adjectives to adverbs<a name=\"Linzen\"></a>[<sup>[2]</sup>](#Linzennote).\n",
    "\n",
    "In the follow-up paper, “Distributed Representations of Words and Phrases and their Compositionality,” Mikolov introduces an extension to the model, focusing on the word phrases and adding distributed representations of words and phrases, which allowed for even more robust vector representations and semantic relationships like idiomatic phrases [3]. The paper showed connections from cities to their respective newspaper outlets and countries to their airlines [3].\n",
    "\n",
    "However, the research of Tal Linzen showed that there are potential limitations in relying on the cosine similarity for analogical reasoning to emerge, and the analogous relationships presented in the original papers break down when you reverse them [1]. The analogical reasoning can be partially explained by the model picking up the closest neighbor word and not the relative difference in similarity in the analogous pair [1]. Therefore, there is a need for further research looking into the relative neighborhoods and analogical reasoning capabilities of Word2Vec models. \n",
    "We will present an extensive analysis of the clustering of differences between pairs of Word2Vec embeddings, in order to examine the semantic and vector representation relationship of the words, gain insight into what drives the apparent vector-based analogical reasoning, and expand the potential areas of research on the interpretability of language models.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "It is well known that embeddings generated by Word2Vec models respect relationships between words. For example, the differences between the vectors for countries and their respective capitals are very similar between all such pairs. In this sense, we get “relationship vectors”, which capture an entire relationship with one vector, and allow for reasoning by analogy. However, most observations of this have been hand-picked, and have considered only a couple of possible relationships. As such, we would like to tackle the issue of investigating all possible “relationship vectors”, so that we are not leaving out potentially overlooked members of these relationships or overlooked relationships entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "You should have a strong idea of what dataset(s) will be used to accomplish this project. \n",
    "\n",
    "If you know what (some) of the data you will use, please give the following information for each dataset:\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc will be needed\n",
    "\n",
    "If you don't yet know what your dataset(s) will be, you should describe what you desire in terms of the above bullets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Why might your solution work? Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination. Get creative!\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
